{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification Task 1 - No Pretraining.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMOhgSgcg90rNiLDNRMckFD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Save Images"],"metadata":{"id":"WlOaGlbLEzE1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAv91oYvx5zf"},"outputs":[],"source":["from google.colab import drive\n","import os\n","import cv2\n","from matplotlib import pyplot as plt\n","import random"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"xKChtdrsE3tv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["covidPath = \"/content/drive/MyDrive/project-yr-3/covid/\"\n","tbPath = \"/content/drive/MyDrive/project-yr-3/tb/\"\n","normalPath = \"/content/drive/MyDrive/project-yr-3/normal/\"\n","\n","random.shuffle(os.listdir(covidPath))\n","random.shuffle(os.listdir(tbPath))\n","random.shuffle(os.listdir(normalPath))"],"metadata":{"id":"VrOyoqtKE4gk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["covidList = []\n","tbList = []\n","normalList = []\n","\n","img_size = 224\n","total_imgs = 1000\n","\n","# extract files from data folders\n","# covid\n","count = 0\n","for img in os.listdir(covidPath):\n","  if (count < (total_imgs/3)):\n","    img_array = cv2.imread(os.path.join(covidPath,img), cv2.IMREAD_GRAYSCALE)\n","    new_array = cv2.resize(img_array, (img_size, img_size))\n","    #new_array = cv2.GaussianBlur(new_array, (random.randrange(1, 25, 2), random.randrange(1, 25, 2)), 0)\n","    covidList.append(new_array.copy())\n","    count += 1\n","\n","# tb\n","count = 0\n","for img in os.listdir(tbPath):\n","  if (count < (total_imgs/3)):\n","    img_array = cv2.imread(os.path.join(tbPath,img), cv2.IMREAD_GRAYSCALE)\n","    new_array = cv2.resize(img_array, (img_size, img_size))\n","    #new_array = cv2.GaussianBlur(new_array, (random.randrange(1, 25, 2), random.randrange(1, 25, 2)), 0)\n","    tbList.append(new_array.copy())\n","    count += 1\n","\n","# normal\n","count = 0\n","for img in os.listdir(normalPath):\n","  if (count < (total_imgs/3)):\n","    img_array = cv2.imread(os.path.join(normalPath,img), cv2.IMREAD_GRAYSCALE)\n","    new_array = cv2.resize(img_array, (img_size, img_size))\n","    #new_array = cv2.GaussianBlur(new_array, (random.randrange(1, 25, 2), random.randrange(1, 25, 2)), 0)\n","    normalList.append(new_array.copy())\n","    count += 1"],"metadata":{"id":"vhJ3C4pKFMM2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show first image in image list\n","print(\"Total images: \" + str(len(covidList)) + \"\\n\")\n","print(\"Image 1:\")\n","for i in range (0,5):\n","  print(covidList[i].shape)\n","  plt.imshow(covidList[i], cmap='gray')\n","  plt.show()"],"metadata":{"id":"NxioCU4YQ9Dj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create directories for each label\n","mainDir = '/content/gdrive/imgs/'\n","\n","for i in range(1,4):\n","  if not os.path.exists(mainDir + str(i) + '/'):\n","      os.makedirs(mainDir + str(i) + '/')"],"metadata":{"id":"k4aasfYefPq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# add list images to corresponding directories\n","myPath = os.path.abspath(mainDir)\n","\n","i = 1\n","for i in range(len(covidList)):\n","  plt.imsave(myPath + '/1/' + str(i) + '.jpg', covidList[i])\n","  i += 1\n","\n","i = 1\n","for i in range(len(tbList)):\n","  plt.imsave(myPath + '/2/' + str(i) + '.jpg', tbList[i])\n","  i += 1\n","\n","i = 1\n","for i in range(len(normalList)):\n","  plt.imsave(myPath + '/3/' + str(i) + '.jpg', normalList[i])\n","  i += 1"],"metadata":{"id":"d24lLcq3hNpf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Counting images in directories\n","total = 0\n","print(\"Number of images per class: \")\n","for i in range(1,4):\n","  num = len(os.listdir(mainDir + '/' + str(i)))\n","  total = total + num\n","  print(\"Disease \" + str(i) + \": \" + str(num))\n","print(\"Total images: \"+ str(total) + '\\n')"],"metadata":{"id":"v4gLK2M17HPP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BwoQktsDChCb"},"source":["# Load Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nm1_T9p46uLA"},"outputs":[],"source":["import random\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xk3N_JNxE7KY"},"outputs":[],"source":["training_data = []\n","\n","def create_training_data():\n","  for i in range(0,3):\n","    path = os.path.join(mainDir, str(i+1))\n","    class_num = i\n","    for img in os.listdir(path):\n","      try:\n","        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n","        new_array = cv2.resize(img_array, (img_size, img_size))\n","        #new_array = cv2.GaussianBlur(new_array, (random.randrange(1, 25, 2), random.randrange(1, 25, 2)), 0)\n","        training_data.append([new_array, class_num])\n","      except Exception as e:\n","        pass\n","\n","create_training_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sHbj2kbQHNts"},"outputs":[],"source":["print(len(training_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RwVfb0yIHU8X"},"outputs":[],"source":["random.shuffle(training_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0Roo3-kHvLH"},"outputs":[],"source":["for sample in training_data[:10]:\n","  print(sample[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrZLENSHHyhC"},"outputs":[],"source":["X = []\n","y = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bH2a8JawH-PK"},"outputs":[],"source":["for features, label in training_data:\n","  X.append(features)\n","  y.append(label)\n","\n","X = np.array(X).reshape(-1, img_size, img_size, 1)\n","y = np.array(y)"]},{"cell_type":"markdown","metadata":{"id":"3AFDYlcNJjIy"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bl1IhZ5E6_Yg"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow import keras\n","from keras import regularizers\n","from keras.layers import GaussianNoise"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDFVc3wVV8Ry"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WIe1cqcJMDC"},"outputs":[],"source":["#prepare data for training\n","#normalise value\n","X_train = X_train/255.0\n","X_test = X_test/255.0\n","\n","#transform labels to one-hot encoding\n","y_train = keras.utils.to_categorical(y_train, 3)\n","y_test = keras.utils.to_categorical(y_test, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UoTN0T6fLe12"},"outputs":[],"source":["model = keras.models.Sequential()\n","\n","model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=X_train.shape[1:]))\n","model.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu', kernel_regularizer=regularizers.l2(l=0.01)))\n","model.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add(keras.layers.Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=regularizers.l2(l=0.01)))\n","model.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n","\n","model.add(keras.layers.Flatten())\n","\n","model.add(keras.layers.Dense(64, activation='relu'))\n","model.add(keras.layers.Dense(128, activation='relu'))\n","\n","model.add(keras.layers.Dense(3, activation='softmax'))\n","\n","model.summary()\n","model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics='acc')"]},{"cell_type":"markdown","source":["#Select and Fit Model"],"metadata":{"id":"rsPacloBXqCp"}},{"cell_type":"code","source":["#callback for 90% accuracy\n","import tensorflow as tf\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if(logs.get('val_acc')>=0.90):\n","      print(\"\\nReached 90% accuracy so cancelling training!\")\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()"],"metadata":{"id":"O8P5W4MaXs5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#dot_img_file = '/tmp/model_1.png'\n","#tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"],"metadata":{"id":"t8GftVlTRkoy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSnlbIglMd9w"},"outputs":[],"source":["history = model.fit(X_train, y_train, batch_size=32, epochs=40, validation_split=0.1, callbacks=[callbacks])"]},{"cell_type":"markdown","metadata":{"id":"-f9IswncgwJG"},"source":["# Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4kxdt-v-EqI"},"outputs":[],"source":["from sklearn import metrics\n","import seaborn as sn\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QN4lQ_5kQ_u7"},"outputs":[],"source":["f, ax = plt.subplots()\n","ax.plot([None] + history.history['acc'], 'o-')\n","ax.plot([None] + history.history['val_acc'], 'x-')\n","\n","#plot legend and use the best location automatically: loc = 0\n","ax.legend(['Training Accuracy', 'Validation Accuracy'], loc = 0)\n","ax.set_title('Training/Validation Accuracy Per Epoch \\nLung Disease Classification: Without Pre-training')\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('Accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bj8Md_4QWQ4w"},"outputs":[],"source":["f, ax = plt.subplots()\n","ax.plot([None] + history.history['loss'], 'o-')\n","ax.plot([None] + history.history['val_loss'], 'x-')\n","\n","#plot legend and use the best location automatically: loc = 0\n","ax.legend(['Training Loss', 'Validation Loss'], loc = 0)\n","ax.set_title('Training/Validation Loss Per Epoch \\nLung Disease Classification: Without Pre-training')\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('Loss')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"arXrXxxwWexA"},"outputs":[],"source":["score = model.evaluate(X_test, y_test, verbose = 0) \n","\n","print(model.metrics_names)\n","print(score)\n","\n","print('Test loss:', round(score[0], 4)) \n","print('Test accuracy:', round(score[1], 4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZkfj7RmWgfM"},"outputs":[],"source":["y_pred = model.predict(X_test)\n","\n","labels = ['covid', 'tb', 'normal']\n","matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n","print(matrix)\n","\n","matrix_norm = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1), normalize='true')\n","print(matrix_norm)"]},{"cell_type":"code","source":["df_cfm = pd.DataFrame(matrix, index = labels, columns = labels)\n","plt.figure(figsize = (10,7))\n","cfm_plot = sn.heatmap(df_cfm, annot=True, fmt='g')\n","cfm_plot.set_title('Confusion Matrix \\nLung Disease Classification: Without Pre-training')\n","cfm_plot.set_xlabel('Predicted Label')\n","cfm_plot.set_ylabel('True Label')\n","\n","df_cfm = pd.DataFrame(matrix_norm, index = labels, columns = labels)\n","plt.figure(figsize = (10,7))\n","cfm_plot = sn.heatmap(df_cfm, annot=True, fmt='g')\n","cfm_plot.set_title('Normalised Confusion Matrix \\nLung Disease Classification: Without Pre-training')\n","cfm_plot.set_xlabel('Predicted Label')\n","cfm_plot.set_ylabel('True Label')"],"metadata":{"id":"wGVgpuc8YfN8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0H-AycV86-Ex"},"outputs":[],"source":["#test out-of-sample images by SEPERATE UPLOAD\n","import numpy as np\n","from google.colab import files\n","from keras.preprocessing import image\n","\n","uploaded = files.upload()\n","\n","def find_class(classes):\n","  maxValue = np.amax(classes)\n","  index = np.where(classes == np.amax(classes))\n","  result = ''\n","  if index[1] == 0:\n","    result = \"covid\"\n","  elif index[1] == 1:\n","    result = \"tb\"\n","  else:\n","    result = \"normal\"\n","  return result\n","\n","for fn in uploaded.keys():\n","  path = fn\n","  img_array = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","  new_array = cv2.resize(img_array, (img_size, img_size))\n","  x = image.img_to_array(new_array)\n","  x = np.expand_dims(x, axis = 0)\n","\n","  images = np.vstack([x])\n","  classes = model.predict(images, batch_size=1)\n","  print(fn)\n","\n","  plt.imshow(new_array, cmap='gray')\n","  plt.title(\"prediction: \" + str(find_class(classes)))\n","  plt.show()"]},{"cell_type":"code","source":[""],"metadata":{"id":"-ZMhtk1MXKss"},"execution_count":null,"outputs":[]}]}